# Test 1

The old, broken example from https://python.useinstructor.com/hub/llama-cpp-python/#llama-cpp-python but swapping the model to llama 3

# Test 2

Using instructor openai to point at vllm's openai compatible server, running llama 3

# Test 3

As with test 2, but not doing the partial streaming thing. Cant remember why.


# Test 4

Using updated, fixed instructor llama-cpp-python example that uses `patch` rather than `from_openai`

# Test 5

As with test 4 - but trying a tricker schema.

# Test 6

As with test 5, but adding the ability to augment (fill blanks) of an existing model.